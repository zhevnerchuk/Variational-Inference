{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from math import pi, log\n",
    "from BBSVI import SVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Example\n",
    "\n",
    "Assume we have mixture of some Gaussians and we want to distinguish them. Here we do it using Black Box SVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generating data\n",
    "\n",
    "std = 1\n",
    "mu = np.array([-5, 5])\n",
    "num_components = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "num_samples = 1000\n",
    "\n",
    "components = np.random.choice(num_components, size=num_samples, p=np.array([1/2, 1/2]))\n",
    "data = torch.Tensor(np.random.normal(mu[components], std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define two classes for prior and variational distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GaussianMixture:\n",
    "    def __init__(self, num_components, log_std=0):\n",
    "        \n",
    "        self.log_std = nn.Parameter(torch.Tensor([log_std]))\n",
    "        self.means = nn.Parameter(1 * torch.randn(num_components, requires_grad=True))\n",
    "        self.weights = nn.Parameter(torch.ones(num_components, requires_grad=True) / num_components)\n",
    "        self.weights_distr = torch.distributions.Categorical(probs=self.weights)\n",
    "        self.weights_distr.probs = self.weights\n",
    "        self.components_distrs = [torch.distributions.Normal(self.means[i], \n",
    "                                                             torch.exp(self.log_std)) for i in range(num_components)]\n",
    "        self.parameters = [self.log_std, self.means]\n",
    "\n",
    "    def log_likelihood_global(self, beta):\n",
    "        return torch.zeros(1, requires_grad=True)\n",
    "    \n",
    "    def log_likelihood_local(self, z, beta):\n",
    "        return self.weights_distr.log_prob(z)\n",
    "    \n",
    "    def log_likelihood_joint(self, x, z, beta):\n",
    "        mix_term = self.weights_distr.log_prob(z)\n",
    "        normal_term = self.components_distrs[z].log_prob(x)\n",
    "        return mix_term + normal_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VariationalDistribution:\n",
    "    def __init__(self, num_components, data_size):\n",
    "        self.num_components = num_components\n",
    "        self.probs = [torch.nn.Parameter(torch.ones(num_components) / num_components) for _ in range(data_size)]\n",
    "        self.distrs = [torch.distributions.Categorical(probs=self.probs[i]) for i in range(data_size)]\n",
    "        self.global_parameters = []\n",
    "        self.local_parameters = self.probs\n",
    "        \n",
    "    def sample_global(self, num_samples = 1):\n",
    "        return torch.zeros(1)\n",
    "    \n",
    "    def sample_local(self, beta, idx):\n",
    "        return self.distrs[idx].sample()\n",
    "    \n",
    "    def log_likelihood_global(self, beta):\n",
    "        return torch.zeros(1, requires_grad=True)\n",
    "    \n",
    "    def log_likelihood_local(self, z, idx):\n",
    "        return self.distrs[idx].log_prob(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define prior, variational distribution and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = GaussianMixture(num_components)\n",
    "var = VariationalDistribution(num_components, num_samples)\n",
    "opt = torch.optim.Adam([{'params': var.local_parameters},\n",
    "                        {'params': var.global_parameters},\n",
    "                        {'params': prior.parameters}], lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svi = SVI(data, prior, var, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial means:   \t -1.01 \t 0.55\n",
      "..................................................\n",
      "Predicted means: \t -5.94 \t 4.63\n",
      "Real means:      \t -5.00 \t 5.00\n",
      "Mixture components detecting accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "predicted_mu = prior.means.data.numpy()\n",
    "print('Initial means:   \\t %.2f \\t %.2f' % (predicted_mu[0], predicted_mu[1]))\n",
    "svi.make_inference(num_steps=50, shuffle=False, loss='bb2', print_progress=True)\n",
    "\n",
    "predicted_mu = prior.means.data.numpy()\n",
    "print('Predicted means: \\t %.2f \\t %.2f' % (predicted_mu[0], predicted_mu[1]))\n",
    "print('Real means:      \\t %.2f \\t %.2f' % (mu[0], mu[1]))\n",
    "\n",
    "predicted_components = np.array([torch.max(var.probs[i], dim=-1)[1].data.numpy() for i in range(num_samples)])\n",
    "accuracy = np.sum(predicted_components == components) / len(predicted_components)\n",
    "accuracy = max(accuracy, 1 - accuracy)\n",
    "print('Mixture components detecting accuracy: %.2f %%' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** SVI strongly depends on the initialization configuration. If you fail to reproduce good result, try to reinitialize initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
