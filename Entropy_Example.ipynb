{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from math import pi, log\n",
    "from BBSVI import SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu = 2.5\n",
    "np.random.seed(42)\n",
    "num_samples = 1000\n",
    "data = torch.Tensor(np.random.normal(mu, 1, size=num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Prior:\n",
    "    def __init__(self):\n",
    "        self.prior = torch.distributions.Normal(torch.zeros(1), torch.ones(1))\n",
    "        \n",
    "    def log_likelihood_global(self, beta):\n",
    "        return self.prior.log_prob(beta)\n",
    "    \n",
    "    def log_likelihood_joint(self, x, z, beta):\n",
    "        cond = torch.distributions.Normal(beta, torch.ones(1))\n",
    "        return cond.log_prob(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VariationalDistribution:\n",
    "    def __init__(self):\n",
    "        self.mu = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "        self.sigma = nn.Parameter(torch.ones(1), requires_grad=True)\n",
    "        self.distr = torch.distributions.Normal(self.mu, self.sigma)\n",
    "        self.parameters = [self.mu, self.sigma]\n",
    "        \n",
    "    def sample_global(self):\n",
    "        return self.distr.rsample()\n",
    "    \n",
    "    def sample_local(self, beta, idx):\n",
    "        return None\n",
    "    \n",
    "    def entropy(self):\n",
    "        return self.distr.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytical_mu = torch.sum(data) / (1 + num_samples)\n",
    "analytical_sigma = np.sqrt(1 / (1 + num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = Prior()\n",
    "var = VariationalDistribution()\n",
    "opt = torch.optim.Adam(var.parameters, lr=1e-3)\n",
    "svi = SVI(data, prior, var, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior params:                \t mu=0.00 \t sigma=1.00\n",
      "..................................................\n",
      "VI Posterior params:         \t mu=2.50 \t sigma=0.02\n",
      "Analytical Posterior params: \t mu=2.52 \t sigma=0.03\n"
     ]
    }
   ],
   "source": [
    "num_steps = 50\n",
    "discounter_schedule = torch.Tensor(np.linspace(0, 1, num_steps))\n",
    "print('Prior params:                \\t mu=%.2f \\t sigma=%.2f' % (var.mu, var.sigma))\n",
    "svi.make_inference(num_steps=num_steps, loss='entropy', print_progress=True, discounter_schedule=discounter_schedule)\n",
    "print('VI Posterior params:         \\t mu=%.2f \\t sigma=%.2f' % (var.mu, var.sigma))\n",
    "print('Analytical Posterior params: \\t mu=%.2f \\t sigma=%.2f' % (analytical_mu, analytical_sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
